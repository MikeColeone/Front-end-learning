[“保姆级”大文件上传教程 :切片上传 + 断点续传 + 秒传 + 暂停上传-CSDN博客](https://blog.csdn.net/cpc980209/article/details/140093954)

# 为什么大文件上传刷新页面保持上传进度只能用indexdb不能使用sessionstorage?或者localStorage?



---

### 一、核心原因对比

| **特性**     | **IndexedDB**           | **sessionStorage**      |
| ---------- | ----------------------- | ----------------------- |
| **存储容量**   | 50MB~1GB（浏览器允许扩展）       | 约 **5MB**               |
| **数据生命周期** | **持久存储**（除非手动删除）        | **页面会话结束即销毁**（刷新/关闭标签页） |
| **数据结构支持** | 支持 **二进制数据**、对象、索引等复杂结构 | 仅支持 **字符串键值对**          |
| **读写性能**   | 异步操作，适合 **大体积数据分片**     | 同步操作，**阻塞主线程**          |
| **适用场景**   | 大文件分片、断点续传、离线缓存         | 临时表单数据、页面级轻量状态          |

---

### 二、为何 IndexedDB 更合适？

#### 1. **存储容量需求**

- **大文件分片**：假设上传 1GB 文件，分片为 1MB/片 → 需存储 **1000 个分片**及相关元数据
- **sessionStorage**：5MB 容量根本不够存储分片数据
- **IndexedDB**：轻松存储数百分片和上传状态

#### 2. **二进制数据支持**

```javascript
// IndexedDB 直接存储文件分片
const chunk = file.slice(offset, offset + chunkSize);
transaction.objectStore('chunks').add({ id: chunkId, data: chunk });

// sessionStorage 需转成 Base64（体积膨胀 33%）
const base64Chunk = await blobToBase64(chunk);
sessionStorage.setItem(chunkId, base64Chunk);
```

#### 3. **断点续传能力**

- **网络中断**：IndexedDB 保留所有分片记录，恢复后可继续上传
- **页面崩溃/刷新**：从数据库读取已上传分片列表，跳过已传部分

#### 4. **异步非阻塞**

```javascript
// IndexedDB 异步操作（不阻塞主线程）
const tx = db.transaction('chunks', 'readwrite');
tx.oncomplete = () => console.log('存储完成');

// sessionStorage 同步操作（大数据量会卡顿）
for (let i=0; i<1000; i++) {
  sessionStorage.setItem(`chunk-${i}`, data); // 页面冻结！
}
```

#### 5. **数据持久性**

- **场景**：用户上传到一半去吃午饭，关闭浏览器 → 下午重新打开页面
- **IndexedDB**：保留所有进度，用户可继续上传
- **sessionStorage**：数据丢失，需重新上传

---

### 三、实现方案示例

#### 1. 核心架构设计

```javascript
class UploadManager {
  constructor() {
    this.db = await this._initDB(); // 初始化 IndexedDB
  }

  async _initDB() {
    // 创建数据库结构
    const request = indexedDB.open('UploadDB', 1);
    request.onupgradeneeded = (e) => {
      const db = e.target.result;
      if (!db.objectStoreNames.contains('files')) {
        const store = db.createObjectStore('files', { keyPath: 'fileId' });
        store.createIndex('chunks', 'chunks', { unique: false });
      }
    };
    return await request;
  }

  async saveChunk(fileId, chunk) {
    const tx = this.db.transaction('files', 'readwrite');
    const store = tx.objectStore('files');
    const record = await store.get(fileId);
    if (record) {
      record.chunks.push(chunk);
      await store.put(record);
    } else {
      await store.add({ fileId, chunks: [chunk] });
    }
  }

  async resumeUpload(fileId) {
    const tx = this.db.transaction('files', 'readonly');
    const store = tx.objectStore('files');
    const record = await store.get(fileId);
    return record?.chunks || [];
  }
}
```

#### 2. 工作流程

1. **开始上传** → 生成唯一 `fileId` 并初始化数据库记录
2. **分片存储** → 每个分片保存到 IndexedDB
3. **上传中断** → 记录最后成功分片的 ID
4. **恢复上传** → 从数据库加载已传分片列表，继续后续分片

---

### 四、为什么不选其他方案？

| **方案**              | **问题**                      |
| ------------------- | --------------------------- |
| **LocalStorage**    | 同源策略限制、同步阻塞、容量小（5MB）        |
| **Cookies**         | 容量极小（4KB）、每次请求携带浪费带宽        |
| **Service Worker**  | 需要配合 Cache API 使用，无法直接持久化数据 |
| **File System API** | 浏览器兼容性差（仅 Chrome 支持）        |

---

### 五、性能优化技巧

1. **分片压缩**  
   
   ```javascript
   // 上传前使用 Compression Streams API 压缩
   const compressedStream = chunk.stream().pipeThrough(new CompressionStream('gzip'));
   ```

2. **批量事务**  
   
   ```javascript
   // 每 10 个分片批量提交一次事务
   const BATCH_SIZE = 10;
   let batch = [];
   for (const chunk of chunks) {
     batch.push(chunk);
     if (batch.length >= BATCH_SIZE) {
       await db.batchSave(batch);
       batch = [];
     }
   }
   ```

3. **清理策略**  
   
   ```javascript
   // 上传完成后自动清理
   async function cleanup(fileId) {
     const tx = db.transaction('files', 'readwrite');
     await tx.objectStore('files').delete(fileId);
   }
   ```

---

**总结**：IndexedDB 凭借其 **大容量存储**、**二进制支持** 和 **持久化特性**，成为实现可靠大文件断点续传的唯一可行选择，而 sessionStorage 因容量和生命周期限制完全无法胜任此场景。



---


